%%% SOME OF THIS CODE IS ADAPTED FROM THE VENERABLE withesis.cls

%% BEGIN PAGESTYLE

%%% You can pick a pagestyle if you want; see the memoir class
%%% documentation for more info.  The default ``deposit'' option meets
%%% the UW thesis typesetting requirements but is probably
%%% unsatisfactory for making a version of your dissertation that
%%% won't be deposited to the graduate school (e.g. for web or a nice
%%% printed copy)

\chapterstyle{deposit}
\pagestyle{deposit}

\chapter{Related Work}

\section{Gaze in Human Communication}
\label{sec:BackgroundHumanGaze}

The ability to follow another person's gaze and infer the direction of their attention emerges in the first year of life \citep{scaife1975infant}. Following another person's gaze enables establishment of reference \citep{dentremont2007early}, inference of intent \citep{mumme2007actions}, and engagement in joint attention with the person \citep{dentremont2007early}. Joint attention facilitates learning and comprehension by associating speech utterances with objects and information in the environment. This ability also develops at an early age and is crucial for the acquisition of language \citep{woodward2005infants}. In dialogue, moving the eyes closely in step with a speaker allows the listener to use spatial structure to organize information in the same way as the speaker \citep{richardson2005looking}. Addressees also make use of the speaker's gaze as a cue for disambiguating references \citep{hanna2007speakers,preissler2005role}. Conversational partners' shared gaze toward referents is higher while they speak about those objects \citep{bard1988referring}.

Humans infer other people's direction of attention by integrating information about their eye gaze direction, head orientation \citep{hietanen1999does}, and body orientation \citep{langton2000eyes,hietanen2002social,pomianowska2011socialcues}. Changes in body orientation occur relatively rarely during interaction compared to gaze shifts involving eye and head movements and indicate larger shifts in attention and mutual involvement \citep{kendon1973visible,schegloff1998bodytorque}. People tend to reorient their bodies to avoid head rotations larger than 90$^{\circ}$ when gazing at someone \citep{kendon1973visible}. Changes in body orientation also occur when a new party joins a conversation in order to reconfigure the conversational formation \citep{kendon2010spacing}.

People are particularly sensitive to the gaze of others \citep{argyle1976gaze}. This is interpreted as being attended to and, depending on the context of interaction, can lead to either discomfort from feeling observed or genuine social interaction \citep{argyle1976gaze}. A person who makes increased eye contact is associated with greater perceived dynamism, likeability, and believability \citep{beebe1976effects}. These people are also seen as being more truthful or credible \citep{argyle1976gaze}. Studies have shown that that people who spend more time gazing at their conversational partner receive higher socioemotional evaluations \citep{goldberg1969visual}, while gaze aversion produces consistently negative effects in impressions of attraction, credibility, and relational communication \citep{burgoon1986communicative}.

Gaze is a significant contributor to \emph{immediacy}---the degree of perceived physical or psychological closeness between people \citep{mehrabian1966immediacy}. Students from primary school through college have been shown to learn better when they are gazed at by the lecturer \citep{burgoon1986communicative, fry1975effects, sherwood1987facilitative, otteson1980effect}. Learning in these cases was usually measured by the students' performance on recall tasks. In a similar study, gazing into the camera during a video link conversation was shown to increase the recall of the viewer at the other end \citep{fullwood2006effect}. Gaze's positive effect on recall is usually attributed to its role as an arousal stimulus, which increases attentional focus and therefore enhances memory \cite{kelley1988effects}.

\section{Gaze in Computer Animation}
\label{sec:BackgroundGazeAnimation}

Prior work in gaze animation is broadly surveyed in~\citep{ruhland2015gazereview} and has largely focused on the automated synthesis of natural gaze behavior given certain input information. I distinguish between \emph{low-level} models for gaze synthesis, which generate kinematics of gaze movements from a specification of where the character should be looking, and \emph{high-level} models, which determine \emph{where} to look based on high-level information. My proposed approach relates to prior work in both categories.

\subsection{Low-level Gaze Synthesis}

One of the most important eye movements in gaze is the \emph{saccade}---fast eyeball movement between fixations. Much of the prior work in gaze animation has focused on synthesis of natural saccadic gaze using statistical models learned from recorded eye movements~\cite{deng2005automated,le2012live,lee2002eyes}. Saccades are integral components of larger gaze shifts, where they occur in coordination with head and upper body movements. Researchers have proposed several models of eye-head coordination in gaze ~\cite{peters2010animating,lance2010expressive,andrist2012headeye}. These models expose parameters for controlling how much the head should turn toward the target over the course of the gaze shift, allowing a degree of control over head posture. They achieve motion naturalness in different ways. The Expressive Gaze Model~\cite{lance2010expressive} makes use of recorded motion data to add expressiveness to gaze movements, while the model by~\citet{andrist2012headeye} is procedural but uses kinematics derived from neurophysiological measurements of gaze. The data-driven model by~\citet{ma2009natural} is notable because it infers natural eye movements from motion-captured head movements. In my research, I propose a gaze inference and synthesis approach that does not infer eye movements directly; rather, we infer a high-level specification from which the overall gaze movement can be synthesized.

Several gaze synthesis models also incorporate coordinated torso movements~\citep{thiebaux2009realtime,lance2010expressive,heck2007automated,grillon2009crowds}. The model by~\citet{heck2007automated} is data-driven---turning of the torso is achieved by blending example torso postures. ~\citet{grillon2009crowds} use an inverse kinematics approach to adapt the body posture toward the target. ~\citet{thiebaux2009realtime} is the only model that affords parametric control over eye, head, and torso coordination, at the expense of naturalness.  The key feature of our model is the use of neurophysiology-based gaze kinematics, which ensure plausible movement quality across the model's parameter range.

\subsection{High-level Gaze Synthesis}

High-level gaze synthesis is concerned with synthesizing gaze behavior with respect to high-level perceptual, emotional, cognitive, and social competencies of the character. Visual attention models determine where the character should be looking based on visual features of the environment~\citep{peters2003attention}. Examples include models of idle gaze in interactive virtual environments~\citep{khullar2001look,cafaro2009animating,grillon2009crowds}, which help situate the character in the environment and make them appear more lifelike. Another category of models synthesize gaze behavior to signal the character's emotions and cognitive state. ~\citet{queiroz2007automatic} and ~\citet{lance2010expressive} have analyzed gaze in animated films and derived models for synthesis of emotionally expressive gaze. ~\citet{lance2007emotionally} have explored layering emotionally expressive content onto coordinated head and torso movements in gaze. Other researchers have proposed models for generating patterns of eye movements parametrized by emotional~\citet{li2012emotional} and cognitive~\citet{lee2007rickel} states of the character.

%Gaze is an important nonverbal cue in human conversations and a large body of work in gaze synthesis deals with synthesis of conversational gaze for virtual agents conversing with humans. Researchers have explored synthesis of gaze patterns that match the current conversational state~\cite{pelachaud2003modelling,masuko2007headeye}, gaze cues as nonverbal feedback while the agent is listening to the user~\cite{gratch2007rapport}, mutual gaze during storytelling to improve the agent's social presence~\cite{bee2010gaze}, averted gaze to regulate conversational turns and express cognitive state~\cite{andrist2013aversion}, gaze driven by prosodic and semantic features of speech~\cite{zoric2011oncreating,le2012live,marsella2013virtual}, etc. In the field of multimodal interaction, researchers have proposed systems for synthesis of coordinated nonverbal behaviors---such as gaze---from text annotations; examples include BodyChat~\cite{vilhjalmsson1998bodychat}, BEAT~\cite{cassell1999fully}, Spark~\cite{vilhjalmsson2004animating}, and systems based on Behavior Markup Language (BML)~\cite{vilhjalmsson2007bml}.
Gaze is an important nonverbal cue in human interaction, and a large body of work in gaze synthesis deals with synthesis of conversational gaze for virtual agents interacting with humans. Many effects of gaze in human-human interaction (Section~\ref{sec:BackgroundHumanGaze}) have also been observed in interaction with virtual agents and social robots. A virtual agent can employ gaze as an attention cue and assist people in localizing task-relevant objects in the environment~\citet{bailly2010gaze}. Mutual gaze during storytelling can improve the agent's social presence~\cite{bee2010gaze} and facilitate greater recall of the story~\citet{mutlu2006storytelling}. Virtual agent's head posture during gaze has significant effects on the interaction~\citet{andrist2012designing}---when the agent aligns its head more with the camera, it is perceived as more engaging, trustworthy, and likeable, while greater head alignment with task objects in the environment facilitates better recall of those objects. 