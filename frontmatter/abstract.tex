In order to perform effectively as virtual actors, teachers, trainers, and storytellers, animated characters need to utilize \emph{directed gaze}---coordinated eye, head, and body movements toward a new focus of attention---to capture and manage the viewers' attention, directing it toward important objects and information and triggering high-level processes such as engagement and learning. The goal of my research is to make it easier for animators to produce directed gaze animation that looks visually plausible for the current scenario and is effective as a mechanism for attention management, engagement, and learning. My work will consist of developing and empirically evaluating a novel approach for authoring effective directed gaze animation, that will be robust to the character's body motion, morphology, and environment layout, and cost-effective with respect to authoring time and required expertise. In the proposed approach, directed gaze will be represented as a sequence of \emph{gaze shifts} toward specific targets; techniques will be provided for automated inference and manual editing of gaze behaviors based on this representation. The components of the work will be the following: (1) a procedural animation model for synthesis of individual gaze shifts; (2) techniques for automated adaptation of gaze shift motion to virtual characters with non-realistic and non-human morphologies; (3) an approach for authoring \emph{plausible} directed gaze animation, consisting of automated inference from body motion and environment and an accessible tool for manual editing; (4) an extension of the approach to support automated inference of \emph{effective} gaze that achieves animator-specified communicative goals; (5) a study with human participants evaluating the effectiveness of synthesized gaze animation on a virtual agent in a teaching scenario. 