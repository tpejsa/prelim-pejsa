%%% SOME OF THIS CODE IS ADAPTED FROM THE VENERABLE withesis.cls

%% BEGIN PAGESTYLE

%%% You can pick a pagestyle if you want; see the memoir class
%%% documentation for more info.  The default ``deposit'' option meets
%%% the UW thesis typesetting requirements but is probably
%%% unsatisfactory for making a version of your dissertation that
%%% won't be deposited to the graduate school (e.g. for web or a nice
%%% printed copy)

\chapterstyle{deposit}
\pagestyle{deposit}

\chapter{Introduction}

Animated characters need to communicate effectively with humans, whether as cartoon actors in animated films or as animated teachers and storytellers giving virtual presentations, lectures, and task demonstrations. One important capability required for effective communication in these contexts is \emph{directed gaze}. I define directed gaze as coordinated movement of the eyes, head, and body toward target objects or information in the environment. People use directed gaze to indicate the focus of their attention to others, which facilitates a range of social and cognitive processes. For example, teachers and storytellers can gaze upon their audience to make the presentation more immediate, engaging, and instructive~\citep{fullwood2006effect,sherwood1987facilitative,otteson1980effect}. People can use gaze to redirect the attention of others to objects and information in the environment through the mechanism of \emph{joint attention}~\citep{dentremont2007early}. The ability to cue attention using gaze enables high-level meaning to be communicated more effectively during interactions---people ground linguistic references to objects by looking at them~\citep{hanna2007speakers,preissler2005role} and gaze also serves as a predictor of their intention to perform physical actions~\citep{strabala2012learning}. Well-animated gaze of a cartoon character or virtual agent can achieve the same effects. Professional animators expend much effort into animating believable gaze movements that capture the audience's attention and direct it toward the most important thing on the screen, while in the area of human-agent interaction, a growing number of studies~\citep{andrist2012designing,andrist2013aversion,mutlu2006storytelling} suggest that animated agents with appropriately designed gaze behavior perform better in educational and socially assistive roles.

Animating directed gaze that successfully fulfills these communicative functions is a challenging problem. A necessary, but insufficient requirement for gaze animation is that it must look \emph{plausible}---the character's gaze must look like something a human might do in the same situation, without unnaturalness and visual artifacts that might distract from what the character is communicating.
%Professional animators strive for "lifelike", "believable"... - character looks and behaves like a sentient being with personality, emotions, goals...
%That is a much higher bar and not one we strive to achieve - we care about enabling specific communicative effects that make the character good at its task (teaching, storytelling, training...) and not about creating a simulacrum of human life
Furthermore, gaze animation must be \emph{effective}---it must achieve communicative effects specified by the animator. Effective gaze is able to direct the viewer's attention, engage them, and help them understand the character's intents. The effectiveness of gaze is empirically verifiable by means of studies with human participants. Finally, the process of producing gaze animation must be \emph{robust} and \emph{cost-effective}. While a skilled animator might be able to hand-author plausible and effective gaze for a particular animated scenario, that approach is neither robust nor cost-effective---animation production using traditional keyframing tools requires considerable expertise and labor, and the resulting animation is specific to the current scenario and not robust to changes in the character's morphology, actions, and virtual environment. Motion capture is a robust solution for body animation, but not for gaze---a typical motion capture setup does not capture eye movements and results usually need to be hand-edited after the fact. Methods for automated synthesis of gaze animation (surveyed in Section~\ref{sec:BackgroundGazeAnimation}) are limited in different ways: they may apply only to a specific context (e.g., just conversational gaze) or specific types of gaze movements (e.g., just the eyes and head, but no body), they do not consider the problem of combining gaze with the (potentially complex and varied) body motion, they may not afford sufficient parametric control or manual editing support to achieve the desired communicative effect, and their effectiveness is often not validated empirically.

My thesis is that plausible, effective directed gaze animation can be produced in a robust and cost-effective way using an authoring approach based on automated, parametrically controlled synthesis and augmented by manual editing. The key idea of my approach is to represent directed gaze as a sequence of \emph{gaze annotations}, where each annotation concisely describes a gaze shift toward a single target (which can be an environment object or the camera.) Given an animated scenario with a character performing a sequence of actions (encoded in its body motion) within a virtual environment, the proposed approach will automatically infer a gaze annotation sequence describing a \emph{plausible} gaze behavior. The approach will allow for accessible manual editing of the gaze behavior by editing the annotation sequence. To achieve \emph{effective} gaze, the behavior inference model will expose attention parameters allowing the animator to specify the types of gaze patterns that will occur in the output behavior and achieve specific communicative effects. Given the annotation sequence, corresponding gaze shift movements will be synthesized using a procedural model of human gaze shift kinematics, adapted to the character's morphology, and layered onto the original body motion. The proposed approach will be \emph{robust} to variations in character morphology, body motion, environment layout, and communicative goals, as well as \emph{cost-effective} in requiring minimal expertise and many fewer editing operations than traditional keyframing to produce equivalent results.

My work will consist of developing the technical components of the approach and evaluations of its robustness, cost-effectiveness, as well as plausibility and effectiveness of the resulting gaze animation. Each of the components will constitute a distinct contribution. Technical components of the work will include: (1) a model for synthesis of individual \emph{directed gaze shifts} supporting coordinated eye, head, and torso movements; (2) \emph{stylized gaze} techniques for adaptation of gaze shift movements to non-realistic and non-human character morphologies; (3) an approach for authoring \emph{plausible gaze}, consisting of an automated gaze inference model, a manual editing tool, and techniques for layering gaze animation onto body motion; (4) an extension of this approach to support automated inference of \emph{effective} gaze that achieves animator-specified communicative effects. In addition, my work will include (5) an \emph{evaluation}, in a study with human participants, of the effectiveness of authored gaze behaviors on a virtual agent giving physical task demonstrations. Besides serving as an evaluation, this study will inform the design of virtual agents' gaze behaviors that make them more effective in the roles of teachers, trainers, and storytellers, and as such it will constitute a distinct contribution.

The focus of my work is on gaze animation in \emph{non-interactive} scenarios, where the character acts out a script and does not respond to input from the viewer. However, I hypothesize that the approach will generalize to the gaze of characters in interactive scenarios, such as characters and avatars in games and embodied conversational agents interacting with users in ``serious'' applications. The approach will operate on fairly generic, low-level inputs---captured (or hand-animated) body motion, 3D modeled environment, virtual camera, and a few optional, animator-specifiable parameters---and produce a similarly generic output---gaze animation. Such features are commonplace in wide range of interactive systems.
% TODO: get rid of this, or say it elsewhere, in fewer words

In the remainder of this document, I give a review of related work, followed by an overview of the components of my research. For each component, I will provide a discussion of its relevance to my thesis, overview of its technical implementation, and a plan for its evaluation.